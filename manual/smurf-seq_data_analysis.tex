\documentclass[11pt]{article}

\usepackage{fullpage,times}
\usepackage{graphicx}
\usepackage{float}
\usepackage[hidelinks]{hyperref}

\title{Data analysis procedure for SMURF-seq reads}
\date{}

\newenvironment{cmd}
{\list{}{
    \parsep=0em
    \itemindent=17pt
    \listparindent=50pt
    \leftmargin=0in
    \rightmargin=0in
  }\item[] \ttfamily \$}
{\endlist}

\begin{document}
\maketitle
\tableofcontents

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%% Intro                                                                %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\section{Introduction}
SMURF-seq is a protocol to efficiently sequence short DNA molecules on
a long-read sequencer by randomly ligating them to form
long molecules.
%
The SMURF-seq protocol involves cleaving the genomic DNA into short
fragments. These fragmented molecules are then randomly ligated back
together to form artificial, long DNA molecules. The long re-ligated
molecules are sequenced following the standard MinION library
preparation protocol. After (or possibly concurrent with) sequencing,
the SMURF-seq reads are mapped to the reference genome in a way that
simultaneously splits them into their constituent fragments, each
aligning to a distinct location in the genome (for most fragments).

%
This manual explains how to map SMURF-seq reads, generate copy-number profiles
from the mapped fragments, and perform additional optional analysis of the
sequenced read or the mapped fragments.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%% Mapping SMURF-seq reads                                              %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Mapping SMURF-seq reads}
At this point, we assume that the reads generated from a
SMURF-seq experiment are base-called and are in a fastq or
fasta file.

The reads sequenced using SMURF-seq protocol needs to be mapped to the
reference genome to identify the fragment locations. The reads can be
aligned leveraging long-read mapping tools that are designed for split-read
alignment.

We present the option of aligning SMURF-seq reads using BWA-MEM
\cite{li2013aligning}, Minimap2 \cite{li2018minimap2}, and LAST
\cite{kielbasa2011adaptive}, and we present several parameter
recommendations for each tool.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Prerequisites}
\paragraph{Reference genome:} The CNV analysis procedure described in
section \ref{cnv} makes use of the human reference genome build
\texttt{hg19}, and thus this build has to used to generate CNV profiles
using the procedure described here. However, other reference genomes
can be utilized if the user does not used the procedure in \ref{cnv}

\paragraph{Software required:}
\begin{enumerate}
  \item Mapping tool: One of BWA, Minimap2, or LAST.
  \item samtools \cite{li2009sequence} (version: 1.9)
\end{enumerate}

\paragraph{Environment variables:}
Required only when using the provided scripts for mapping SMURF-seq reads.
The variable \texttt{MAPPER} can be set using:
\begin{cmd}
  export MAPPER=<path to mapping tool>
\end{cmd}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Mapping SMURF-seq reads to the reference genome}

A user has an option of using either of the tools listed above following
the procedure in section \ref{bwa}, \ref{minimap}, or \ref{last}
respectively. We recommend using BWA-MEM as this produced higher
fragment counts.

\subsubsection{Mapping SMURF-seq reads with BWA-MEM}
The download and install instructions for BWA can be found at:
\url{https://github.com/lh3/bwa}

\label{bwa}
\paragraph{Reference genome index creation:}
The reference genome index is created using the command:
\begin{cmd}
  bwa index <genome file>
\end{cmd}
The index occupies approximately 5.14 GB for hg19.

\paragraph{Parameter recommendations:}
The default parameter to map nanopore reads using BWA-MEM is \texttt{-x~ont2d}.
SMURF-seq reads can be aligned using just this option, however, the fragment
lengths were longer than optimal. We recommend using the parameters
\texttt{-A 1 -B 2 -O 0 -E 2} in addition to \texttt{-x~ont2d}. These
parameters constrain the growth of a fragment and their lengths were close to
optimal. To further increase the number of fragments obtained, at the
expense of a longer runtime, the minimum seed length (\texttt{k}) and the
minimum chain weight (\texttt{W}) can be lowered.


\paragraph{Aligning SMURF-seq reads:}
SMURF-seq reads are mapped to the reference genome using for fast mapping:
\begin{cmd}
  bwa mem -x ont2d -A 1 -B 2 -O 0 -E 2 -t <threads> $\backslash$ \par
  <index> <reads>
\end{cmd}
or using to obtain a higher fragment count:
\begin{cmd}
  bwa mem -x ont2d -k 11 -W 5 -A 1 -B 2 -O 0 -E 2 -t <threads> $\backslash$
  \par <index> <reads> > <outfile>.sam
\end{cmd}
The above commands can also be run using the scripts:
\begin{cmd}
  ./map/smurfseq\_BWA\_fast.sh <index> <reads>
\end{cmd}
or
\begin{cmd}
  ./map/smurfseq\_BWA\_frags.sh <index> <reads>
\end{cmd}
\noindent
respectively. These scripts require environment variable \texttt{MAPPER}
set to the location of BWA.



\subsubsection{Mapping SMURF-seq reads with Minimap2}
\label{minimap}

The download and install instructions for Minimap2 can be found at:
\url{https://github.com/lh3/minimap2}

\paragraph{Reference genome index creation (Optional):}
Minimap2 can create minimizer index for the human reference genome in
a few minutes before mapping the reads. Optionally, the
index can be pre-built and saved to save time during mapping with
the command:
\begin{cmd}
  minimap2 -d -w 1 <index name>.mmi <genome file>
\end{cmd}
The index occupies approximately 28GB for hg19. Note that index size
is much larger than when using the default parameter. As explained below,
this option produces a significantly higher fragment count.

\paragraph{Parameter recommendations:}
Minmap2 produces higher fragment counts when the window size (\texttt{w})
is lowered to 1 and the chain weight (\texttt{m}) to 10 than using the
default parameters. However, lowering the window size increases the
genome index size.


\paragraph{Aligning SMURF-seq reads:}
SMURF-seq reads are aligned to the reference genome using:
\begin{cmd}
  minimap2 -a -w 1 -m 10 -t <threads> <genome> <reads> >
    \par <outfile>.sam
\end{cmd}
or using the script:
\begin{cmd}
  ./map/smurfseq\_minimap2.sh <genome file> <reads>
\end{cmd}
This script requires environment variable \texttt{MAPPER} set to the
location of Minimap2.

\subsubsection{Mapping SMURF-seq reads with LAST}
\label{last}

The download and install instructions for LAST can be found at:
\url{http://last.cbrc.jp/}

\paragraph{Reference genome index creation:}
The reference genome index is created using the command:
\begin{cmd}
  lastdb -uNEAR -R01 <index> <genome>
\end{cmd}
The index occupies approximately 15.3GB for hg19.

\paragraph{Parameter recommendations:}
The genome index is created using the seed patter NEAR (1111110) which is
recommended for scheme for finding short-and-strong matches
(\url{http://last.cbrc.jp/doc/last-seeds.html}). The reads are then aligned
to the reference genome using the default parameters.

\paragraph{Aligning SMURF-seq reads:}
SMURF-seq reads are aligned to the reference genome using:
\begin{cmd}
  lastal -Q0 -P<threads> <index> <reads> | last-split |
    \par maf-convert sam > <outfile>.sam
\end{cmd}
or using the script:
\begin{cmd}
  ./map/smurfseq\_last.sh <index> <reads>
\end{cmd}
This script requires environment variable \texttt{MAPPER} set to the
location of LAST.




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Generating mapping statistics}
After the reads are aligned, the number of fragments generated can be
determined using:
\begin{cmd}
  samtools flagstat <mapped file>.sam
\end{cmd}

The number corresponding to the line ``mapped'' in the output of the above
command is the number of fragments generated
mapping. Refer to section \ref{misc} for optional additional analysis of
mapped fragments.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Mapping subsets of reads in parallel}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Test data}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%% CNV profile generation                                               %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Generation of copy-number profiles}
\label{cnv}
CNV profiles were generated using the procedure described in
\cite{baslan2012genome,kendall2014computational} with the
modification employed in
\cite{gerdtsson2018multiplex,malihi2018clonal}.
Briefly, the
human reference genome (hg19) was split into 5k (20k or 50k) bins
containing the an equal number of uniquely mappable locations and
the bin counts were determined using uniquely mapped fragments.
Bins with spuriously high counts (`bad bins', typically around
centromeric and telomeric regions) were masked for
downstream analysis \cite{kendall2014computational}.
This procedure normalizes bin counts for biases correlated with GC
content by fitting a LOWESS curve to the GC content by bin count,
and subtracting the LOWESS estimate from each bin
\cite{kendall2014computational}.
Circular binary segmentation (CBS) {\cite{olshen2004circular}},
implemented in DNAcopy {\cite{seshan2010dnacopy}} package, then
identifies breakpoints in the normalized bin counts.
Following \cite{gerdtsson2018multiplex,malihi2018clonal}, after CBS,
spurious segmentation calls were removed.



\subsection{Prerequisites}
\paragraph{Software required:}
\begin{enumerate}
  \item python
  \item R
\end{enumerate}

\paragraph{Libraries required:}
\begin{enumerate}
  \item DNAcopy (R package) \cite{seshan2010dnacopy}
\end{enumerate}

\subsection{Generating CNV profiles}
At this point, we assume that the sequenced SMURF-seq reads are mapped to the
reference genome and the alignments produced are in a sam file.
Generating CNV profiles from a sam file involves getting the uniquely aligned
fragment, generating the number of fragments that are aligned to each bin, and
generating the segmented CNV profiles using DNAcopy. These step are described
below.

\paragraph{Getting uniquely aligned fragments}
After alignment, some fragments may be ambiguously aligned, i.e. they are
equally likely aligned to two or more locations on the reference genome.
Since the true location of such a fragment cannot be determined they are
removed from copy number analysis.
All fragments aligned with a mapping quality (MAPQ in the sam file) greater
than 0 are considered as uniquely aligned for copy number analysis.
Note that different mappers use different metrics to determine MAPQ. BWA-MEM
sets MAPQ to 0 if there are multiple alignments with the same alignment score
or if an alignment has a low number of matches and the alignment score of
the second best alignment is close to the best alignment.

Uniquely aligned fragments can be generated using the command:
\begin{cmd}
  ./cnv/get\_unique\_maps.py <aligned>.sam > <alinged>.unique.sam
\end{cmd}

\paragraph{Generating bin counts}
The next step in CNV analysis is to determine the number of fragments
aligned to each bin on the reference genome. This is done with the
command:
\begin{cmd}
  ./cnv/get\_bin\_counts.py <alinged>.unique.sam <chrom sizes>
    \par <bin boundaries> <sample name>.bincount.txt <sample name>.stats.txt
\end{cmd}

The files \texttt{<chrom sizes>} and \texttt{<bin boundaries>} contain the
length of hg19 chromosomes and the bin boundaries to determined the counts
respectively. These files are located in the the folders cnv/5k, cnv/20k
and cnv/50k for 5k, 20k, and 50k bin resolutions respectively.

\paragraph{Generating copy number profiles}
Finally, the CNV profiles are generated by segmenting the ratio to mean of
the bin counts. The profile can be obtained using:
\begin{cmd}
  R CMD BATCH --args <sample name>.bincount.txt <sample name>
    \par <GC content>.txt <bad bins>.txt cnv/cbs.r <outfile>.txt
\end{cmd}

\paragraph{Scripts to generate CNV profiles}
After alignment, CNV profiles can be directly generated using the script:
\begin{cmd}
  ./cnv/cnv-<5k/20k/50k>.sh <aligned>.sam <sample name>
\end{cmd}
This script executes the three steps described above to generate the profiles.
The script requires the environment variable \texttt{SMURFDIR} set to the
location of the smurfseq-scripts repository, using the command:
\begin{cmd}
  export SMURFDIR=<path to smurfseq-scripts dir>
\end{cmd}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%% Misc. analysis                                                       %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Miscellaneous analysis of sequenced reads and mapped fragments}
\label{misc}

\subsection{Read length distribution}

\subsection{Fragment length distribution}

\subsection{Closeness to RE sites}

\subsection{Extracting unaligned bases from reads}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%% References                                                           %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\bibliographystyle{unsrt}
\bibliography{smurf-seq_data_analysis}

\end{document}
